{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "DWF21-template.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rbl96vhD0_yT"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmolsriv/COMP/blob/main/DWF21_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhZg2DIv0_yM"
      },
      "source": [
        "# Data Warehouses Design and Use\n",
        "\n",
        "\n",
        "## Goals\n",
        "The goal of this assignment is to gain experience and practice constructing, populating, and querying  a data warehouse. We will continue to use our ice cream food truck for this exercise. \n",
        "\n",
        "You will be further developing your skills in writing declarative SQL. In addition, you will see the impact of grain size on query time and table size.\n",
        "\n",
        "## Your task\n",
        "Your task is to write SQL code, and fill in some values to a few Python cells, as directed in the assignment. Your notebook must run without error. Be sure to test that you can run all of the cells (except the # LOCALDB cell) from a fresh start, without error.\n",
        "\n",
        "## Grading\n",
        "This assignment is worth 50 points.  The number of points assigned to each component is indicated.\n",
        "\n",
        "## Autograding\n",
        "We will use an autograder for first pass grading of this assignment. In order for our autograder to work, we need to connect your solution to a local database. \n",
        "\n",
        "**DO NOT RUN CELLS THAT START WITH THE COMMENT `# LOCALDB` and do not remove those cells.**\n",
        "\n",
        "For cells that contain your answer, replace the `SELECT 1` SQL code with your solution. Do not change the first line of the cell or remove the following cell.\n",
        "\n",
        "We are using an autograder for the first pass grading. For the autograder to work, you need to complete your work in the appropriate cells and name and order the attributes in your results as directed. \n",
        "\n",
        "**It's critical that you use the attribute names and sort order as directed. If attribute name(s) are not specfied, use the name in the source table.**\n",
        "\n",
        "## Academic Honesty\n",
        "The following level of collaboration is allowed on this assignment: \n",
        "\n",
        "You may discuss the assignment with other class members at a high level. What is not allowed is direct examination of anyone else's SQL code (on a computer, email, whiteboard, etc.) or allowing anyone else to see your SQL  code. You may also use (and in fact are encouraged to use) the PostgreSQL reference manual \n",
        "\n",
        "https://www.postgresql.org/docs/10/index.html\n",
        "\n",
        "You may use the search engine of your choice to look up the syntax for PostgreSQL commands, but may not use it to find answers. Remember to cite your sources!\n",
        "\n",
        "\n",
        "## Useful Information\n",
        "The following PostgreSQL functions may be helpful.\n",
        "\n",
        "EXTRACT EXTRACT(<unit> FROM <attribute>). Can be used to extract hour, month, year, day of week, etc. from dates\n",
        "\n",
        ":: Casts the attribute to the left of the :: to the type specified on the right\n",
        "    \n",
        "## What to submit\n",
        "\n",
        "Submit this jupyter notebook containing your table definitions, queries, code, and results. Be sure to provide code to delete any VIEWs and TABLEs other that the start 4 tables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI72W5bS0_yN"
      },
      "source": [
        "## Background\n",
        "The system we have designed for our ice cream food truck is great for recording orders and sales. However, due to its focus on recipes and tickets, queries to determine strategy (e.g. most popular ingredients, etc.) can be complex. Here, you will construct and populate a Star Schema for ingredient.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c14S7t10_yN"
      },
      "source": [
        "## Data \n",
        "\n",
        "This section describes the tables that provide data for this assignment.\n",
        "\n",
        "\n",
        "We leverage the following base tables in this assignment:\n",
        "\n",
        "* truckEvent: Details of the events where the food truck sold ice cream.  Attributes include:\n",
        "\n",
        "    * EventId: Primary key. Unique id of each event\n",
        "    * EventName: Text name for the event\n",
        "    * EventStart: Start time of the event\n",
        "    * EventPlannedEnd: Time the event was expected to end\n",
        "    * EventActualEnd: Time the event actually ended\n",
        "    * EventStatus: Status indicating if the event is planned, in progress,  completed, or cancelled\n",
        "    * TotalDollarSales: Sum of the selling price of all of the products sold during the event\n",
        "    * TotalNumProducts: Number of products sold during the event \n",
        "    * TotalNumTickets: Number of tickets created during the event \n",
        "\n",
        "* ticket: Details of each set of products purchased together during an event\n",
        "\n",
        "    * TicketId: Unique id of each ticket\n",
        "    * EventId: Id of event where the ticket was created\n",
        "    * TicketTime: Time when the ticket was created\n",
        "    * NumProducts; Number of products purchased together on this ticket\n",
        "    * TotalPrice: Sum of selling price of all products purchased together on this ticket\n",
        "\n",
        "* productSold:  Details about each product sold during an event\n",
        "\n",
        "    * productSoldId: Unique id of each product sold\n",
        "    * ProductCode: Code identifying the product that was sold\n",
        "    * TicketId: Id of the ticket in which this product was sold\n",
        "    * Price: Selling price of the product\n",
        "\n",
        "* saleDetail: Detail about the ingredient(s) used in each product sold\n",
        "    * SaleDetailId: Unique id of each detail\n",
        "    * ProductSoldId: The id of the productSold which this saleDetail is part of\n",
        "    * IngName: Name of the ingredient\n",
        "    * Qty: Quantity of the ingredient\n",
        "    * Unit: Unit of measure of the ingredient\n",
        "    * Detail: Detail / choice made for the ingredient (e.g. **vanilla** or **tall**)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "localdb"
        ],
        "id": "A5MSSHMr0_yN"
      },
      "source": [
        "# LOCALDB\n",
        "# connect to grader database\n",
        "import psycopg2\n",
        "from configparser import ConfigParser\n",
        "\n",
        "def config(filename='.pg_service.conf', section='postgresql'):\n",
        "    # create a parser\n",
        "    parser = ConfigParser()\n",
        "    # read config file\n",
        "    parser.read(filename)\n",
        "\n",
        "    # get section, default to postgresql\n",
        "    db = {}\n",
        "    if parser.has_section(section):\n",
        "        params = parser.items(section)\n",
        "        for param in params:\n",
        "            db[param[0]] = param[1]\n",
        "    else:\n",
        "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
        "\n",
        "    return db\n",
        "\n",
        "params = config()\n",
        "# build the connection string\n",
        "def make_conn_str(params):\n",
        "\n",
        "    return f\"postgresql+psycopg2://{params['user']}:{params['password']}@{params['host']}:{params['port']}/{params['dbname']}\"\n",
        "        \n",
        "# connect to the database\n",
        "conn_str = make_conn_str(params)\n",
        "%load_ext sql\n",
        "%sql $conn_str \n",
        "%config SqlMagic.displaylimit=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-adxbbT0_yO"
      },
      "source": [
        "\n",
        "## Initialization\n",
        "\n",
        "The next cell needs to be run each time you start up Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgXDTtX80_yO",
        "outputId": "ec01ef1a-46bd-4670-ee98-9993935f24f1"
      },
      "source": [
        "# colab install\n",
        "!pip install --upgrade pip\n",
        "!pip install SQLAlchemy==1.3.23\n",
        "!pip install psycopg2-binary\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql start\n",
        "!sudo -u postgres psql -c \"CREATE USER root WITH SUPERUSER\"\n",
        "# set connection\n",
        "%load_ext sql\n",
        "%config SqlMagic.autolimit=100\n",
        "# Limit queries to 100 results. Increase this value if needed, but recognize that your notebook will increase in size as well. %config SqlMagic.displaylimit=100\n",
        "%sql postgresql+psycopg2://@/postgres\n",
        "!sudo -u postgres createdb ricedb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 1.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "Collecting SQLAlchemy==1.3.23\n",
            "  Downloading SQLAlchemy-1.3.23-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
            "     |████████████████████████████████| 1.3 MB 1.7 MB/s            \n",
            "\u001b[?25hInstalling collected packages: SQLAlchemy\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.25\n",
            "    Uninstalling SQLAlchemy-1.4.25:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.25\n",
            "Successfully installed SQLAlchemy-1.3.23\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "     |████████████████████████████████| 3.4 MB 1.8 MB/s            \n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            " * Starting PostgreSQL 10 database server\n",
            "   ...done.\n",
            "CREATE ROLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7FOF2Om0_yO"
      },
      "source": [
        "\n",
        "The following data files are provided for this assignment:\n",
        "\n",
        "* productsold.csv\n",
        "* saledetail.csv\n",
        "* ticket.csv\n",
        "* truckevent.csv\n",
        "\n",
        "Create these tables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ_Aks8K0_yO",
        "outputId": "61e7308f-3531-4615-9490-a2d3d299bd7e"
      },
      "source": [
        "%%sql\n",
        "DROP TABLE IF EXISTS productsold CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS productsold\n",
        "(\n",
        "    productsoldid integer NOT NULL ,\n",
        "    productcode CHAR(3) NOT NULL,\n",
        "    ticketid integer NOT NULL,\n",
        "    price numeric(10,2) NOT NULL,\n",
        "    PRIMARY KEY (productsoldid)\n",
        ");\n",
        "\n",
        "DROP TABLE IF EXISTS salerecord CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS salerecord\n",
        "(\n",
        "    salerecordid integer NOT NULL,\n",
        "    productsoldid integer,\n",
        "    ingname character varying(50)  NOT NULL,\n",
        "    qty numeric(10,2) NOT NULL,\n",
        "    unit character varying(20)  NOT NULL,\n",
        "    detail character varying(50),\n",
        "    PRIMARY KEY (salerecordid)\n",
        ");\n",
        "\n",
        "DROP TABLE IF EXISTS ticket CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS ticket\n",
        "(\n",
        "    ticketid integer NOT NULL,\n",
        "    eventid integer NOT NULL,\n",
        "    tickettime timestamp without time zone NOT NULL,\n",
        "    numproducts integer NOT NULL DEFAULT 0,\n",
        "    totalprice numeric(5,2) NOT NULL DEFAULT 0,\n",
        "    PRIMARY KEY (ticketid)\n",
        ");\n",
        "\n",
        "DROP TABLE IF EXISTS truckevent CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS truckevent\n",
        "(\n",
        "    eventid integer NOT NULL,\n",
        "    eventname character varying(100)  NOT NULL,\n",
        "    eventstart timestamp without time zone,\n",
        "    eventplannedend timestamp without time zone,\n",
        "    eventactualend timestamp without time zone,\n",
        "    eventstatus character varying(30)  NOT NULL,\n",
        "    menuname character varying(30),\n",
        "    totaldollarsales numeric(10,2),\n",
        "    totalnumproducts integer,\n",
        "    totalnumtickets integer,\n",
        "    PRIMARY KEY (eventid)\n",
        ");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1b3HCm60_yP"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSNsyLQt0_yP",
        "outputId": "324dffbd-4c32-4b53-daee-3642e9e8a7aa"
      },
      "source": [
        "%%sql\n",
        "COPY productsold(productsoldid,productcode,ticketid,price) FROM '/content/productsold.csv' CSV HEADER;\n",
        "COPY ticket FROM  '/content/ticket.csv'  CSV  HEADER; \n",
        "COPY salerecord FROM  '/content/salerecord.csv'  CSV HEADER; \n",
        "COPY truckevent FROM  '/content/truckevent.csv'  CSV HEADER; "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "14322 rows affected.\n",
            "3398 rows affected.\n",
            "73096 rows affected.\n",
            "62 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "id": "puDKZPcH0_yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "e4f531ae-3fd6-4185-f173-914d41b67f05"
      },
      "source": [
        "%%sql\n",
        "-- there should be 14322 records \n",
        "SELECT COUNT(1) \n",
        "FROM productsold;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>count</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>14322</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(14322,)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "id": "Bk9y_lkZ0_yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "5d498b0a-3cfa-4013-92d0-29dd8b948147"
      },
      "source": [
        "%%sql\n",
        "-- there should be 3398\n",
        "SELECT COUNT(1) \n",
        "FROM ticket;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>count</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>3398</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(3398,)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "id": "4TVgV-y90_yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "3a9e7713-107c-4dfa-cc12-020da733f2d3"
      },
      "source": [
        "%%sql \n",
        "-- 73096\n",
        "SELECT COUNT(1) \n",
        "FROM salerecord;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>count</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>73096</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(73096,)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ],
        "id": "BvqF0u7G0_yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "7937297c-27e9-4d76-8abb-6e8c37e1b1f3"
      },
      "source": [
        "%%sql \n",
        "-- 62\n",
        "SELECT COUNT(1) \n",
        "FROM truckevent;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>count</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>62</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "[(62,)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B90RCTpK0_yP"
      },
      "source": [
        "## Data Warehouse Structure\n",
        "\n",
        "In order to write the queries specified below, you will need to construct a star schema for **ingredient used** (salerecord).\n",
        "\n",
        "While many star schema are possible, we constain our data warehouse to a fixed set of fact and dimension tables, as follows.\n",
        "\n",
        "Define the following fact and dimension tables. **Use the exact table names provided**. What you call your attributes within each table is up to you. What data you need in each table should be sufficient to answer all of the questions asked.\n",
        "\n",
        "Assign surrogate primary keys and appropriate foreign keys for each table.  When creating your tables, keep in mind that data warehouses trade-off storage space for computation. That is, it is better to precompute facts you might need and store the result in a fact table versus computing them on the fly. Be sure to use good data warehouse design: Don't snowflake your dimensions, denormalize where appropriate, etc. \n",
        "\n",
        "1. Create (1 point each) and populate from the source data (1 point each) the following tables. \n",
        "\n",
        "    1. DateDim: This dimension table should contain a unique, system assigned numeric identifier, as well as attributes that separate out the day, day of the week, month, and year.\n",
        "\n",
        "    1. EventDim: This dimension table is a dimension table based on the truckevent table.  Assign a unique, system identifier as the primary key.\n",
        "\n",
        "    1. TicketDim: This dimension table  a dimension table based on the ticket table.  Assign a unique, system identifier as the primary key.\n",
        "\n",
        "    1. ProductSoldDim:  A dimension table based on the productsold table. Assign a unique, system identifier as the primary key.\n",
        "\n",
        "\n",
        "1. Create (5 points) and populate from the source data (5 points) the following table.\n",
        "\n",
        "    1. IngUsedFact:  A fact table based on the saleRecord table. The attributes should include foreign key references to the aforementioned dimension tables as well as any additional attributes needed to construct the additional fact tables specified and answer the queries specified below.  You should also include a degenerate dimension that should be populated with the saleRecord id that this IngUsedFact record is based on.\n",
        "\n",
        "\n",
        "1. Create (1 point each) and populate from the source data (1 point each) the following tables. \n",
        "\n",
        "    1. IngUsedByDayFact: This fact table should aggregate the contents of IngUsedFact by the date the ingredient was used. The table should have appropriate primary and foreign keys.\n",
        "\n",
        "    1. IngUsedByMonthFact: This table should aggregate the IngUsedFact table by month \\& year and should have appropriate primary and foreign keys.\n",
        "\n",
        "\n",
        "Keep in mind that when you populate your the `IngUsedFact` table, you need to reference the appropriate records in the dimension tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbJAM3yq0_yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cdd4f5-56ec-4fec-aee4-45e690309a3b"
      },
      "source": [
        "%%sql\n",
        "SELECT 1;\n",
        "\n",
        "-- Create the dimension and fact tables\n",
        "\n",
        "DROP TABLE IF EXISTS DateDim CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS DateDim \n",
        "  (id SERIAL PRIMARY KEY,\n",
        "  day integer,\n",
        "  dayofweek integer,\n",
        "  month integer,\n",
        "  year integer\n",
        "  );\n",
        "\n",
        "DROP TABLE IF EXISTS EventDim CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS EventDim \n",
        "  (id SERIAL PRIMARY KEY,\n",
        "    eventname character varying(100)  NOT NULL,\n",
        "    eventstart timestamp without time zone,\n",
        "    eventplannedend timestamp without time zone,\n",
        "    eventactualend timestamp without time zone,\n",
        "    eventstatus character varying(30)  NOT NULL,\n",
        "    menuname character varying(30),\n",
        "    totaldollarsales numeric(10,2),\n",
        "    totalnumproducts integer,\n",
        "    totalnumtickets integer,\n",
        "    eventid integer\n",
        "  );\n",
        "\n",
        "DROP TABLE IF EXISTS TicketDim CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS TicketDim \n",
        "  (id SERIAL PRIMARY KEY,\n",
        "    tickettime timestamp without time zone NOT NULL,\n",
        "    numproducts integer NOT NULL DEFAULT 0,\n",
        "    totalprice numeric(5,2) NOT NULL DEFAULT 0,\n",
        "    ticketid integer\n",
        "  );\n",
        "\n",
        "DROP TABLE IF EXISTS ProductSoldDim CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS ProductSoldDim \n",
        "  (id SERIAL PRIMARY KEY,\n",
        "    productcode CHAR(3) NOT NULL,\n",
        "    price numeric(10,2) NOT NULL,\n",
        "    productsoldid integer\n",
        "  );\n",
        "\n",
        "DROP TABLE IF EXISTS IngUsedFact CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS IngUsedFact \n",
        "  (id SERIAL PRIMARY KEY,\n",
        "    ingname character varying(50)  NOT NULL,\n",
        "    qty numeric(10,2) NOT NULL,\n",
        "    unit character varying(20)  NOT NULL,\n",
        "    detail character varying(50),\n",
        "    productsold integer,\n",
        "    date integer,\n",
        "    event integer,\n",
        "    ticket integer,\n",
        "    salerecordid integer NOT NULL,\n",
        "    CONSTRAINT ingUsedprodsoldfk FOREIGN KEY(productsold) references ProductSoldDim(id),\n",
        "    CONSTRAINT ingUseddatefk FOREIGN KEY(date) references DateDim(id),\n",
        "    CONSTRAINT ingUsedeventfk FOREIGN KEY(event) references EventDim(id),\n",
        "    CONSTRAINT ingUsedticketfk FOREIGN KEY(ticket) references TicketDim(id),\n",
        "    CONSTRAINT ingUsedsalerecordDDfk FOREIGN KEY(salerecordid) references saleRecord(salerecordid)\n",
        "  );\n",
        "\n",
        "DROP TABLE IF EXISTS IngUsedByDayFact CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS IngUsedByDayFact \n",
        "  (date integer,\n",
        "    month integer,\n",
        "    year integer,\n",
        "    ingname character varying(50),\n",
        "    qty numeric(10,2) NOT NULL,\n",
        "    PRIMARY KEY (date, month, year, ingname)\n",
        "  );\n",
        "\n",
        "DROP TABLE IF EXISTS IngUsedByMonthFact CASCADE;\n",
        "CREATE TABLE IF NOT EXISTS IngUsedByMonthFact \n",
        "  (month integer,\n",
        "    year integer,\n",
        "    ingname character varying(50),\n",
        "    qty numeric(10,2) NOT NULL,\n",
        "    PRIMARY KEY (month, year, ingname)\n",
        "  );  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6nr_-YV0_yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de49b33-8e3c-4c3c-f65b-66d838c4f9cd"
      },
      "source": [
        "%%sql\n",
        "-- populate dimension tables\n",
        "SELECT 1;\n",
        "\n",
        "INSERT INTO DateDim \n",
        "(day, dayofweek, month, year) \n",
        "\n",
        "(\n",
        "  SELECT temp.day, temp.dow, temp.month, temp.year\n",
        "    FROM \n",
        "    (\n",
        "      SELECT EXTRACT(DAY FROM tickettime) as day, EXTRACT(DOW FROM tickettime) as dow,\n",
        "      EXTRACT(MONTH FROM tickettime) as month, EXTRACT(YEAR FROM tickettime) as year\n",
        "      FROM ticket \n",
        "      GROUP BY tickettime\n",
        "    ) temp\n",
        "    GROUP BY temp.day, temp.dow, temp.month, temp.year\n",
        ");\n",
        "\n",
        "\n",
        "INSERT INTO EventDim \n",
        "(eventname, eventstart, eventplannedend, eventactualend, eventstatus, menuname, totaldollarsales, totalnumproducts, totalnumtickets, eventid)\n",
        "\n",
        "(\n",
        "  SELECT eventname, eventstart, eventplannedend, eventactualend, eventstatus, menuname, totaldollarsales, totalnumproducts, totalnumtickets, eventid\n",
        "  FROM truckevent\n",
        ");\n",
        "\n",
        "INSERT INTO TicketDim \n",
        "(tickettime, numproducts, totalprice, ticketid)\n",
        "\n",
        "(\n",
        "  SELECT tickettime, numproducts, totalprice, ticketid\n",
        "  FROM ticket\n",
        ");\n",
        "\n",
        "INSERT INTO ProductSoldDim \n",
        "(productcode, price, productsoldid)\n",
        "\n",
        "(\n",
        "  SELECT productcode, price, productsoldid\n",
        "  FROM productsold\n",
        ");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n",
            "67 rows affected.\n",
            "62 rows affected.\n",
            "3398 rows affected.\n",
            "14322 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44jahcme0_yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c03ac2c-a37a-40bb-f667-a34abc7839a7"
      },
      "source": [
        "%%sql\n",
        "-- populate fact tables\n",
        "SELECT 1;\n",
        "\n",
        "INSERT INTO IngUsedFact  \n",
        "(ingname, qty, unit, detail, productsold, date, event, ticket, salerecordid)\n",
        "\n",
        "(\n",
        "  SELECT sr.ingname, sr.qty, sr.unit, sr.detail, psd.id, dd.id, ed.id, td.id, sr.salerecordid \n",
        "  FROM saleRecord sr \n",
        "    JOIN productsold ps\n",
        "      ON sr.productsoldid = ps.productsoldid \n",
        "    JOIN ticket t \n",
        "      ON t.ticketid = ps.ticketid \n",
        "    JOIN truckevent te \n",
        "      ON te.eventid = t.eventid\n",
        "    JOIN DateDim dd\n",
        "      ON dd.day = EXTRACT(DAY FROM t.tickettime) AND dd.dayofweek = EXTRACT(DOW FROM t.tickettime) AND \n",
        "      dd. month = EXTRACT(MONTH FROM t.tickettime) AND dd.year = EXTRACT(YEAR FROM t.tickettime) \n",
        "    JOIN ProductSoldDim psd \n",
        "      ON psd.productsoldid = ps.productsoldid \n",
        "    JOIN TicketDim td \n",
        "      ON td.ticketid = t.ticketid \n",
        "    JOIN EventDim ed \n",
        "      ON ed.eventid = t.eventid\n",
        ");\n",
        "\n",
        "INSERT INTO IngUsedByDayFact  \n",
        "(date, month, year, ingname, qty)\n",
        "\n",
        "(\n",
        "  SELECT dd.day, dd.month, dd.year, iuf.ingname, sum(iuf.qty)\n",
        "  FROM IngUsedFact iuf  \n",
        "    JOIN DateDim dd\n",
        "      ON dd.id = iuf.date \n",
        "  GROUP BY dd.day, dd.month, dd.year, iuf.ingname\n",
        ");\n",
        "\n",
        "INSERT INTO IngUsedByMonthFact  \n",
        "(month, year, ingname, qty)\n",
        "\n",
        "(\n",
        "  SELECT dd.month, dd.year, iuf.ingname, sum(iuf.qty)\n",
        "  FROM IngUsedFact iuf  \n",
        "    JOIN DateDim dd\n",
        "      ON dd.id = iuf.date \n",
        "  GROUP BY dd.month, dd.year, iuf.ingname\n",
        ");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql+psycopg2://@/postgres\n",
            "1 rows affected.\n",
            "73096 rows affected.\n",
            "872 rows affected.\n",
            "194 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bhuw2270_yQ"
      },
      "source": [
        "## Queries\n",
        "\n",
        "Your data warehouse should be able to answer the following questions. The star schema structure described above should enable you to answer these questions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB0nYOXI0_yQ"
      },
      "source": [
        "1. (3 points) How big are your `IngUsedFact`, `IngUsedFactByDay`, and `IngUsedFactByMonth` tables? Provide the row count.\n",
        "\n",
        " `IngUsedFact`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62qlVszi0_yQ"
      },
      "source": [
        "%%sql py_var_IngUsedFact_num <<\n",
        "SElECT COUNT(1) FROM IngUsedFact;\n",
        "--IngUsedFact num records\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSK5AC-0_yQ"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q01a = py_var_IngUsedFact_num.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q01a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r43T3GOc0_yR"
      },
      "source": [
        "`IngUsedFactByDay`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHpZsjaf0_yR"
      },
      "source": [
        "%%sql py_var_IngUsedByDayFact_num <<\n",
        "SElECT COUNT(1) FROM IngUsedByDayFact;\n",
        "--IngUsedByDayFact num records\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzWOiQZX0_yR"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q01b = py_var_IngUsedByDayFact_num.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q01b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjf5OKBQ0_yR"
      },
      "source": [
        "`IngUsedFactByMonth` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgbEyeyi0_yR"
      },
      "source": [
        "%%sql py_var_IngUsedByMonthFact_num <<\n",
        "SELECT COUNT(1) FROM IngUsedByMonthFact;\n",
        "--IngUsedByMonthFact num records\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEzNjiiw0_yR"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q01c = py_var_IngUsedByMonthFact_num.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q01c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4HPVR0Q0_yR"
      },
      "source": [
        "2 (0 points) Plot the number of records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkaaJ0s-0_yR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "tables = ('IngUsedFact', 'IngUsedByDayFact', 'IngUsedByMonthFact')\n",
        "y_pos = np.arange(len(tables))\n",
        "records = [py_var_IngUsedFact_num[0][0], py_var_IngUsedByDayFact_num[0][0], py_var_IngUsedByMonthFact_num[0][0]]\n",
        "plt.bar(tables, records)\n",
        "plt.ylabel('Records')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auSK5HGU0_yR"
      },
      "source": [
        "3. (1 point) Describe the shape of the plot as it relates to the number of records. Why does the data look this way?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsntFFTK0_yR"
      },
      "source": [
        "-- your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAFj1qv20_yR"
      },
      "source": [
        "4. (4 points) Compute the minimum, maximum, and average price per product per ticket for events that started on or after 6 PM. Round each value to 2 decimal places.\n",
        "\n",
        "Return `minPrice`, `maxPrice`, `avgPrice`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kf-Xqn70_yR"
      },
      "source": [
        "%%sql py_var_productPrice <<\n",
        "SELECT 1 -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmnvoGDI0_yR"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q04 = py_var_productPrice.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q04"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl-eL4AB0_yR"
      },
      "source": [
        "5. (4 points)  When measured by ounces, did the truck sell more vanilla ice cream in July 2017 or August  2017? Write a **single query** that gives you the answer to this question. You may use views.  Return the number of the month. Your answer should be 6 or 7. Use the `IngUsedByMonthFact` table and time your answer. \n",
        "\n",
        "Name the attribute `monthSold`.\n",
        "\n",
        "You can get the time by using ```EXPLAIN ANALYZE``` in the query cell\n",
        "\n",
        "Report the run time. Provide your query and results. You may run the query twice, once to get the timing and once to get the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScObOert0_yR"
      },
      "source": [
        "%%sql py_var_moreSalesMonthFact <<\n",
        "SELECT 1; -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uMMO3q70_yR"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q05 = py_var_moreSalesMonthFact.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK56AuHP0_yR"
      },
      "source": [
        "Time your query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF3SXyL20_yS"
      },
      "source": [
        "%%sql\n",
        "EXPLAIN ANALYZE\n",
        "SELECT 1; -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTURwc8M0_yS"
      },
      "source": [
        "6. (1 point) Now, write and run an analogous query on the `IngUsedByDayFact` table. Report the run time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vpF7qrr0_yS"
      },
      "source": [
        "%%sql py_var_moreSalesDayFact <<\n",
        "SELECT 1; -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzVAdLzv0_yS"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q06 = py_var_moreSalesDayFact.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q06"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIkhvd3F0_yS"
      },
      "source": [
        "Time your query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K-otEXG0_yS"
      },
      "source": [
        "%%sql\n",
        "EXPLAIN ANALYZE\n",
        "SELECT 1 -- your code here;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8MI7tnO0_yS"
      },
      "source": [
        "7. (1 point) Now, write and run an analogous query on the `IngUsedFact` table. Report the run time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al-YPi1f0_yS"
      },
      "source": [
        "%%sql py_var_moreSalesFact <<\n",
        "SELECT 1; -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY5GILSa0_yS"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q07 = py_var_moreSalesFact.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q07"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EggN86_j0_yS"
      },
      "source": [
        "Time your query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmidQZfM0_yS"
      },
      "source": [
        "%%sql\n",
        "EXPLAIN ANALYZE\n",
        "SELECT  1;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TInXOuLd0_yS"
      },
      "source": [
        "%%sql\n",
        "EXPLAIN ANALYZE\n",
        "\n",
        "SELECT monthSold \n",
        "FROM flavorByMonth\n",
        "WHERE totalqty = (\n",
        "    SELECT MAX(totalqty)\n",
        "    FROM flavorByMonth);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bjc6N9F0_yS"
      },
      "source": [
        "8. (1 point) Plot the times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkYaxayV0_yS"
      },
      "source": [
        "tables = ('IngUsedFact', 'IngUsedByDayFact', 'IngUsedByMonthFact')\n",
        "y_pos = np.arange(len(tables))\n",
        "# REPLACE 1, 2, 3 with your values. MAKE SURE THEY ARE IN THE CORRECT ORDER!\n",
        "records = [1, 2, 3]\n",
        "plt.bar(tables, records)\n",
        "plt.ylabel('Time')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nrMTkvm0_yS"
      },
      "source": [
        "9. (4 points) Write and run the following query: List the detail names and total quantity of the least popular, but non-zero valued 3 toppings on cone products - these are productcodes: `c1, c2, c3,` and `wc`, by total quantity used (in this case 'ounce'). Note that ```no topping``` is considered a topping choice. Don't worry about ties, just return the least popular 3 toppings.\n",
        "\n",
        "Return the `detail` and `qty`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtJgrgbm0_yS"
      },
      "source": [
        "%%sql py_var_toppings <<\n",
        "SELECT 1; -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPe9k8Np0_yS"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q09 = py_var_toppings.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q09"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh_sKIzj0_yS"
      },
      "source": [
        "10. (4 points) Which day of the week (a number: 0 = Sunday, 6 = Saturday) has the highest sales of floats? (product code `fl`) by number sold? Return the total and  the day of week index in your query.\n",
        "\n",
        "Return `total` (total number sold) and `dayofweek`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwTFBV3D0_yT"
      },
      "source": [
        "%%sql py_var_mostSales <<\n",
        "SELECT 1; -- your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh0gE5xu0_yT"
      },
      "source": [
        "# do not modify or delete this cell\n",
        "df_q10 = py_var_mostSales.DataFrame() # Save the result of this task for grading purposes\n",
        "df_q10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbl96vhD0_yT"
      },
      "source": [
        "## Clean up!\n",
        "\n",
        "(5 points) Drop any TABLEs and VIEWs you created, including the fact and dimension tables. DO NOT drop the following tables:\n",
        "\n",
        "* productSold\n",
        "* ticket\n",
        "* salesRecord\n",
        "* truckEvent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKrbZq1T0_yT"
      },
      "source": [
        "%%sql\n",
        "DROP VIEW IF EXISTS maxDOW;\n",
        "DROP VIEW IF EXISTS maxVariance;\n",
        "DROP VIEW IF EXISTS avgQtyPerMin;\n",
        "DROP VIEW IF EXISTS qtyPerMin;\n",
        "DROP VIEW IF EXISTS flavorByMonth;\n",
        "DROP VIEW IF EXISTS flavorByMonthUsingDay;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmQGV75S0_yT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}